{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b77601bf",
   "metadata": {},
   "source": [
    "### loading and looking at the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb027e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import pytorch_lightning as pl\n",
    "import time\n",
    "import logging\n",
    "import re\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "from torchmetrics import Metric\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from termcolor import colored\n",
    "from itertools import chain\n",
    "from string import punctuation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import pipeline\n",
    "from transformers import AdamW, AutoTokenizer, AutoModelForSeq2SeqLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fa52df-c685-4063-85ab-9539fc32ff2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install pytorch-lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad9d8be",
   "metadata": {},
   "source": [
    " ### creating the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68aa480d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# extract questions and answers (incl. empty)\n",
    "def extract_qa(json_file):\n",
    "    with open(json_file) as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    data_rows = []\n",
    "    for i in range(220,230):\n",
    "        questions = data[\"data\"][i][\"paragraphs\"]\n",
    "\n",
    "        for question in questions:\n",
    "            context = question[\"context\"]\n",
    "            for question_and_answers in question[\"qas\"]:\n",
    "                if question_and_answers[\"answers\"] == []:\n",
    "                    question = question_and_answers[\"question\"]\n",
    "                    answers = [{'text':'', 'answer_start': 0}]\n",
    "                else:\n",
    "                    question = question_and_answers[\"question\"]\n",
    "                    answers = question_and_answers[\"answers\"]\n",
    "\n",
    "                for answer in answers:\n",
    "                    answer_text = answer[\"text\"]\n",
    "                    answer_start = answer[\"answer_start\"]\n",
    "                    answer_end = answer_start + len(answer_text)\n",
    "\n",
    "                    data_rows.append({\n",
    "                        \"question\": question,\n",
    "                        \"context\": context,\n",
    "                        \"answer_text\": answer_text,\n",
    "                        \"answer_start\": answer_start,\n",
    "                        \"answer_end\": answer_end\n",
    "                    })\n",
    "    return pd.DataFrame(data_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4497bf74",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = extract_qa('data/CUADv1.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f11776",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670e5ee1-60ce-408c-877b-a51b2b8cb868",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f15be5a-51e1-484e-861c-da166552902b",
   "metadata": {},
   "source": [
    "### Looking at samples and coloring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07988863",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# look at one example question_\n",
    "sample_question = df.iloc[2]\n",
    "sample_question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946a21c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# colour the answer\n",
    "def color_answer(question):\n",
    "    answer_start, answer_end = question['answer_start'], question['answer_end']\n",
    "    context = question[\"context\"]\n",
    "    \n",
    "    return colored(context[: answer_start], \"white\") + colored(context[answer_start : answer_end + 1], \"blue\") + colored(context[answer_end + 1:], \"white\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5026d24a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(color_answer(sample_question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a80141d",
   "metadata": {},
   "source": [
    "### Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5a00f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/macaw-3b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9bc704-28ca-45db-9d01-c5d091a42ef6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cdf830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CUAD(Dataset):\n",
    "    def __init__(self, data, tokenizer, source_max_token_len, target_max_token_len):\n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.data = data\n",
    "        self.source_max_token_len = 512\n",
    "        self.target_max_token_len = 512\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        data_row = self.data.iloc[index]\n",
    "        \n",
    "        source_encoding = tokenizer(\n",
    "        data_row[\"question\"],\n",
    "        data_row[\"context\"],\n",
    "        max_length=self.source_max_token_len,\n",
    "        padding = \"max_length\",\n",
    "        truncation = 'only_second',\n",
    "        return_attention_mask = True,\n",
    "        add_special_tokens = True,\n",
    "        return_tensors= 'pt')\n",
    "        \n",
    "        target_encoding = tokenizer(\n",
    "        data_row['answer_text'],\n",
    "        max_length=self.target_max_token_len,\n",
    "        padding = \"max_length\",\n",
    "        truncation= True,\n",
    "        return_attention_mask=True,\n",
    "        add_special_tokens = True,\n",
    "        return_tensors = 'pt'\n",
    "        )\n",
    "        \n",
    "        labels = target_encoding[\"input_ids\"]\n",
    "        labels[labels == 0] = -100\n",
    "        \n",
    "        return dict(\n",
    "            question = data_row[\"question\"],\n",
    "            context = data_row[\"context\"],\n",
    "            answer_text = data_row[\"answer_text\"],\n",
    "            input_ids = source_encoding[\"input_ids\"].flatten(),\n",
    "            attention_mask = source_encoding[\"attention_mask\"].flatten(),\n",
    "            labels = labels.flatten(),\n",
    "            decoder_attention_mask = target_encoding[\"attention_mask\"].flatten()\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa2b735",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#sample_dataset = CUAD(df, tokenizer, 396, 32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd3b96a-ea45-432b-8b87-63367d9ae7b4",
   "metadata": {},
   "source": [
    "### Balanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ecf136-3021-4906-8e84-af905aa74539",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_dataset_pos_mask(df):\n",
    "    \"\"\"\n",
    "    Returns a list, pos_mask, where pos_mask[i] indicates is True if the ith example in the dataset is positive\n",
    "    (i.e. it contains some text that should be highlighted) and False otherwise.\n",
    "    \"\"\"\n",
    "    return np.array((df[\"answer_text\"] != '').to_list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4dc9748-8b31-467b-88cb-51c5ed91c5cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_balanced_dataset(dataset, df):\n",
    "    \"\"\"\n",
    "    returns a new dataset, where positive and negative examples are approximately balanced\n",
    "    \"\"\"\n",
    "    pos_mask = get_dataset_pos_mask(df)\n",
    "    neg_mask = [~mask for mask in pos_mask]\n",
    "    npos, nneg = np.sum(pos_mask), np.sum(neg_mask)\n",
    "\n",
    "    neg_keep_frac = npos / nneg  # So that in expectation there will be npos negative examples (--> balanced)\n",
    "    neg_keep_mask = [mask and np.random.random() < 0.2 for mask in neg_mask]\n",
    "    \n",
    "    # keep all positive examples and subset of negative examples\n",
    "    keep_mask = [pos_mask[i] or neg_keep_mask[i] for i in range(len(pos_mask))]\n",
    "    keep_indices = [i for i in range(len(keep_mask)) if keep_mask[i]]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        subset_dataset = torch.utils.data.Subset(dataset, keep_indices)\n",
    "    return subset_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbb0fa5-6009-4e1a-8461-77c93ad5e8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_balanced_dataset(sample_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1e1524-b237-4af7-a2af-d3f20940d80e",
   "metadata": {},
   "source": [
    "### Train/test-split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3d404f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df, val_df = train_test_split(df, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c8415ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df.shape, val_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079d925c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CUADDataModule(pl.LightningDataModule):\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        train_df,\n",
    "        test_df,\n",
    "        tokenizer,\n",
    "        batch_size = 4,\n",
    "        source_max_token_len = 512,\n",
    "        target_max_token_len = 512):\n",
    "\n",
    "        super().__init__()\n",
    "        self.batch_size = batch_size\n",
    "        self.train_df = train_df\n",
    "        self.test_df = test_df\n",
    "        self.tokenizer = tokenizer\n",
    "        self.source_max_token_len = source_max_token_len\n",
    "        self.target_max_token_len = target_max_token_len\n",
    "\n",
    "    def setup(self, stage = None):\n",
    "        self.train_dataset = get_balanced_dataset(CUAD(\n",
    "            self.train_df,\n",
    "            self.tokenizer,\n",
    "            self.source_max_token_len,\n",
    "            self.target_max_token_len\n",
    "        ), self.train_df)\n",
    "        \n",
    "        self.test_dataset = get_balanced_dataset(CUAD(\n",
    "            self.test_df,\n",
    "            self.tokenizer,\n",
    "            self.source_max_token_len,\n",
    "            self.target_max_token_len\n",
    "        ), self.test_df)\n",
    "    \n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "        self.train_dataset,\n",
    "        batch_size= self.batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=4)\n",
    "    \n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "        self.test_dataset,\n",
    "        batch_size=1,\n",
    "        num_workers=4)\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "        self.test_dataset,\n",
    "        batch_size=1,\n",
    "        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc83c12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 2\n",
    "EPOCHS = 2\n",
    "\n",
    "data_module = CUADDataModule(train_df, val_df, tokenizer, batch_size=BATCH_SIZE)\n",
    "data_module.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edcf45b0",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3933fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CUADModel(pl.LightningModule):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/macaw-3b\")\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask, decoder_attention_mask, labels = None):\n",
    "        output = self.model(\n",
    "        input_ids = input_ids,\n",
    "        attention_mask = attention_mask,\n",
    "        decoder_attention_mask = decoder_attention_mask,\n",
    "        labels = labels)\n",
    "        \n",
    "        return output.loss, output.logits\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, decoder_attention_mask, labels)\n",
    "        self.log(\"train_loss\", loss, prog_bar=True, logger = True)\n",
    "        return loss\n",
    "    \n",
    "    def validation_step(self, batch , batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, decoder_attention_mask, labels)\n",
    "        self.log(\"val_loss\", loss, prog_bar=True, logger = True)\n",
    "        return loss\n",
    "    \n",
    "    def test_step(self, batch, batch_idx):\n",
    "        input_ids = batch[\"input_ids\"]\n",
    "        attention_mask = batch[\"attention_mask\"]\n",
    "        labels = batch[\"labels\"]\n",
    "        decoder_attention_mask = batch[\"decoder_attention_mask\"]\n",
    "        loss, outputs = self(input_ids, attention_mask, decoder_attention_mask, labels)\n",
    "        self.log(\"test_loss\", loss, prog_bar=True, logger = True)\n",
    "        return loss\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return AdamW(self.parameters(), lr = 0.00003)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92912a62-eca3-4ab0-8d11-d35f5885efef",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a3e495-bb8f-4993-adaf-8ec6967d4a59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = CUADModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e799ae09",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath = \"cpoints\",\n",
    "    filename = \"best-checkpoint\",\n",
    "    save_top_k = 1,\n",
    "    verbose = True,\n",
    "    monitor = \"val_loss\",\n",
    "    mode = \"min\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135afe82",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer = pl.Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs = EPOCHS,\n",
    "    accelerator = \"gpu\",\n",
    "    devices = 1,\n",
    "    log_every_n_steps=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be84e169-1744-4785-88a6-40bae4208788",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f0c8b22-5468-40cf-afec-4f4fb9da08e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%tensorboard --logdir . --bind_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e25c33d-7d3f-47c4-8261-3c5122891601",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473914cb-5773-4226-b62b-baa0c00caf1e",
   "metadata": {},
   "source": [
    "#### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6dced8f-7edc-4753-8391-434946e83bbc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.fit(checkpoint_model, data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b168d94-cd4a-4ea2-9207-884404efbcc0",
   "metadata": {},
   "source": [
    "#### Train from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55aab6d4-2211-4c64-adfd-0e0414d2c122",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_model = CUADModel.load_from_checkpoint(\"/notebooks/cpoints/best-checkpoint-v4.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8099b31-5947-4f73-ac65-ca585ee88a88",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc58762-8084-49f7-8dd3-7ae7a9bf3edb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model = CUADModel.load_from_checkpoint(\"/notebooks/cpoints/best-checkpoint-v5.ckpt\")\n",
    "trained_model.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055612dc-211e-457f-8b95-edbfbbf261ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answer(question):\n",
    "    source_encoding = tokenizer(\n",
    "        question[\"question\"],\n",
    "        question[\"context\"],\n",
    "        max_length = 512,\n",
    "        padding = \"max_length\",\n",
    "        truncation = \"only_second\",\n",
    "        return_attention_mask = True,\n",
    "        add_special_tokens = True,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "    generated_ids = trained_model.model.generate(\n",
    "        input_ids=source_encoding[\"input_ids\"],\n",
    "        attention_mask = source_encoding[\"attention_mask\"],\n",
    "        num_beams = 1, \n",
    "        max_length = 256, \n",
    "        repetition_penalty = 2.5, \n",
    "        length_penalty = 1.0, \n",
    "        early_stopping = True, use_cache = True)\n",
    "    \n",
    "    preds = [tokenizer.decode(generated_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for generated_id in generated_ids]\n",
    "    return \"\".join(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5905bf-600d-4a5e-8ae8-a340245257c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_answers(df):\n",
    "    source_encoding = tokenizer(\n",
    "        df[\"question\"].to_list(),\n",
    "        df[\"context\"].to_list(),\n",
    "        max_length = 512,\n",
    "        padding = \"max_length\",\n",
    "        truncation = \"only_second\",\n",
    "        return_attention_mask = True,\n",
    "        add_special_tokens = True,\n",
    "        return_tensors = 'pt'\n",
    "    )\n",
    "    generated_ids = trained_model.model.generate(\n",
    "        input_ids=source_encoding[\"input_ids\"],\n",
    "        attention_mask = source_encoding[\"attention_mask\"],\n",
    "        num_beams = 1, \n",
    "        max_length = 512, \n",
    "        repetition_penalty = 2.5, \n",
    "        length_penalty = 1.0, \n",
    "        early_stopping = True, use_cache = True)\n",
    "    \n",
    "    preds_list = [tokenizer.batch_decode(generated_id, skip_special_tokens=True, clean_up_tokenization_spaces=True) for generated_id in generated_ids]\n",
    "    return [\" \".join(preds) for preds in preds_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b2794d-b496-4bb9-9c6e-0e4bab00e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_list = val_df[\"answer_text\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a85d21-9f8e-4fc9-a7be-f65c1ca60863",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = generate_answers(val_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cffcbb7-5f1a-4664-8864-8e093678904a",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d030408-9bd7-42c2-8954-59de8249e8d5",
   "metadata": {},
   "source": [
    "#### Precision/recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5357a66-32ce-4392-9e45-a234639d1c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "IOU_THRESH = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3374c577-d2c3-4f8b-97cc-89ef8642bdc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision_recall_v2(preds, answers):\n",
    "    tp, fp, fn = 0, 0, 0    \n",
    "    # first check if answers is empty\n",
    "    if len(answers) == 0:\n",
    "        if len(preds) > 0:\n",
    "            fp += len(preds)  # false positive for each one\n",
    "    else:\n",
    "        for ans in answers:\n",
    "            match_found = False\n",
    "            if ans == '':\n",
    "                if preds[answers.index(ans)] == ans:\n",
    "                    match_found = True\n",
    "            else:\n",
    "                # check if there is a match\n",
    "                for pred in preds:\n",
    "                    is_match = cosine_similarity(ans, pred) >= IOU_THRESH or ans in pred\n",
    "\n",
    "                    if is_match:\n",
    "                        match_found = True\n",
    "\n",
    "            if match_found:\n",
    "                tp += 1\n",
    "            else:\n",
    "                fn += 1\n",
    "\n",
    "        # now also get any fps by looping through preds\n",
    "        for pred in preds:\n",
    "            # Check if there's a match. if so, don't count (don't want to double count based on the above)\n",
    "            # but if there's no match, then this is a false positive.\n",
    "            # (Note: we get the true positives in the above loop instead of this loop so that we don't double count\n",
    "            # multiple predictions that are matched with the same answer.)\n",
    "            match_found = False\n",
    "            for ans in answers:\n",
    "                is_match = cosine_similarity(ans, pred) >= IOU_THRESH or pred in ans\n",
    "                if is_match:\n",
    "                    match_found = True\n",
    "\n",
    "            if not match_found:\n",
    "                fp += 1\n",
    "\n",
    "    precision = (tp-fp) / tp if tp + fp > 0 else np.nan\n",
    "    recall = tp / (tp + fn) if tp + fn > 0 else np.nan\n",
    "    print(f\"tp: {tp}, fp:{fp}, fn: {fn}, sum: {tp+fp+fn}\")\n",
    "    return print(f\"precision: {precision:.2f}, recall: {recall:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88e0309-83b4-4db4-aa55-4d121fb222eb",
   "metadata": {},
   "source": [
    "### Precision @80% Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cae22df-3100-422e-9bc0-a7e2c7dace16",
   "metadata": {},
   "source": [
    "##### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a695da-cd94-4fda-bd55-628a4cb80704",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558ff34e-9749-411c-aa71-ef7d043e64e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(sent1, sent2):\n",
    "    if sent1 == '':\n",
    "        sent1 = '.'\n",
    "    if sent2 == '':\n",
    "        sent2 = '.'\n",
    "        \n",
    "    X_list = word_tokenize(sent1) \n",
    "    Y_list = word_tokenize(sent2)\n",
    "    \n",
    "    sw = stopwords.words('english') \n",
    "    l1 =[];l2 =[]\n",
    "\n",
    "    # remove stop words from the string\n",
    "    X_set = {w for w in X_list if not w in sw} \n",
    "    Y_set = {w for w in Y_list if not w in sw}\n",
    "\n",
    "    # form a set containing keywords of both strings \n",
    "    rvector = X_set.union(Y_set) \n",
    "    for w in rvector:\n",
    "        if w in X_set: l1.append(1) # create a vector\n",
    "        else: l1.append(0)\n",
    "        if w in Y_set: l2.append(1)\n",
    "        else: l2.append(0)\n",
    "    c = 0\n",
    "\n",
    "    # cosine formula \n",
    "    for i in range(len(rvector)):\n",
    "            c+= l1[i]*l2[i]\n",
    "    cosine = c / float((sum(l1)*sum(l2))**0.5)\n",
    "    \n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48be7b2c-2b01-48bf-907f-04fa32f50d67",
   "metadata": {},
   "source": [
    "### Andre hjelpefunksjoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d88efe-a042-4f71-a55c-c1c92e739ac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_space(sentence):\n",
    "    fixed = \" \".join(sentence.split())\n",
    "    return fixed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
